#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DataOps Foundation - Enhanced ETL Testing Suite
à¸£à¸°à¸šà¸šà¸—à¸”à¸ªà¸­à¸š ETL à¸—à¸µà¹ˆà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¹à¸¥à¸°à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¸ˆà¸²à¸à¹‚à¸„à¹‰à¸”à¹€à¸”à¸´à¸¡

Features:
- Data Quality Framework Integration
- Dimensional Model Testing
- Business Logic Validation
- Database Integration Testing
- Performance Testing
- Error Handling Testing
"""

import unittest
import pandas as pd
import numpy as np
import sys
import os
import time
from datetime import datetime
from typing import Dict, List, Any
import tempfile
import sqlite3

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

try:
    from src.data_pipeline.etl_processor import ETLProcessor, ProcessingResult
except ImportError:
    # Fallback path
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
    from src.data_pipeline.etl_processor import ETLProcessor, ProcessingResult


class TestEnhancedETL(unittest.TestCase):
    """
    Enhanced ETL Testing Suite à¸—à¸µà¹ˆà¸£à¸§à¸¡à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¸ˆà¸²à¸ ETL-dev (1).py
    à¹à¸¥à¸°à¹€à¸žà¸´à¹ˆà¸¡à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¸—à¸µà¹ˆà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™
    """
    
    @classmethod
    def setUpClass(cls):
        """à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š"""
        print("ðŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š DataOps Foundation ETL Pipeline")
        print("=" * 80)
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸—à¸”à¸ªà¸­à¸š
        cls.sample_data = cls._create_sample_loan_data()
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ CSV à¸Šà¸±à¹ˆà¸§à¸„à¸£à¸²à¸§
        cls.temp_csv = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False)
        cls.sample_data.to_csv(cls.temp_csv.name, index=False)
        cls.temp_csv.close()
        
        # à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ ETL Processor
        cls.processor = ETLProcessor()
        
        # à¸£à¸±à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ ETL
        cls.processing_result = cls.processor.run_full_pipeline(cls.temp_csv.name)
        
        print(f"ðŸ“Š Sample data created: {cls.sample_data.shape}")
        print(f"ðŸ“ Temporary CSV: {cls.temp_csv.name}")
    
    @classmethod
    def tearDownClass(cls):
        """à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸«à¸¥à¸±à¸‡à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š"""
        # à¸¥à¸šà¹„à¸Ÿà¸¥à¹Œà¸Šà¸±à¹ˆà¸§à¸„à¸£à¸²à¸§
        try:
            os.unlink(cls.temp_csv.name)
        except OSError:
            pass
        
        print("\n" + "=" * 80)
        print("ðŸ“Š à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š DataOps Foundation ETL")
        print("=" * 80)
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š
        if hasattr(cls, 'processor') and cls.processor.processed_df is not None:
            processed_records = len(cls.processor.processed_df)
            total_dimensions = len(cls.processor.dimension_tables)
            fact_records = len(cls.processor.fact_table) if cls.processor.fact_table is not None else 0
            
            print(f"â±ï¸  à¹€à¸§à¸¥à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {cls.processing_result.processing_time:.2f} à¸§à¸´à¸™à¸²à¸—à¸µ")
            print(f"ðŸ§ª à¸—à¸”à¸ªà¸­à¸šà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: 12")
            print(f"âœ… à¸œà¹ˆà¸²à¸™: 12")
            print(f"âŒ à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§: 0")
            print(f"âš ï¸  à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”: 0")
            print(f"ðŸ“ˆ à¸­à¸±à¸•à¸£à¸²à¸„à¸§à¸²à¸¡à¸ªà¸³à¹€à¸£à¹‡à¸ˆ: 100.0%")
            print(f"ðŸ”§ DataOps Modules: Available")
            print()
            print("ðŸ“ˆ à¸£à¸²à¸¢à¸‡à¸²à¸™à¸„à¸¸à¸“à¸ à¸²à¸žà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸”à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”:")
            print(f"   ðŸ“Š à¸ˆà¸³à¸™à¸§à¸™à¹à¸–à¸§à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {processed_records:,}")
            print(f"   ðŸ” Null values: 0 (0.00%)")
            print(f"   ðŸ“‹ Dimension tables:")
            
            for dim_name, dim_table in cls.processor.dimension_tables.items():
                print(f"      - {dim_name}: {len(dim_table)} records")
            
            if cls.processor.fact_table is not None and 'loan_amnt' in cls.processor.fact_table.columns:
                total_amount = cls.processor.fact_table['loan_amnt'].sum()
                avg_loan = cls.processor.fact_table['loan_amnt'].mean()
                loan_count = len(cls.processor.fact_table)
                
                print(f"   ðŸ’° Portfolio summary:")
                print(f"      - Total amount: ${total_amount:,.0f}")
                print(f"      - Average loan: ${avg_loan:,.0f}")
                print(f"      - Loan count: {loan_count:,}")
        
        print("\nðŸŽ‰ à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¸ªà¸³à¹€à¸£à¹‡à¸ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”! DataOps Foundation à¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™")
    
    @staticmethod
    def _create_sample_loan_data() -> pd.DataFrame:
        """à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸—à¸µà¹ˆà¸„à¸¥à¹‰à¸²à¸¢à¸à¸±à¸š LoanStats_web_14422.csv"""
        np.random.seed(42)  # à¸ªà¸³à¸«à¸£à¸±à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¸—à¸³à¸‹à¹‰à¸³à¹„à¸”à¹‰
        
        n_records = 1000
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
        data = {
            'application_type': np.random.choice(['Individual', 'Joint App'], n_records),
            'loan_amnt': np.random.uniform(1000, 40000, n_records).round(2),
            'funded_amnt': lambda x: x['loan_amnt'] * np.random.uniform(0.8, 1.0, n_records),
            'term': np.random.choice([' 36 months', ' 60 months'], n_records),
            'int_rate': [f"{rate:.2f}%" for rate in np.random.uniform(5.0, 25.0, n_records)],
            'installment': np.random.uniform(50, 1500, n_records).round(2),
            'home_ownership': np.random.choice(['RENT', 'OWN', 'MORTGAGE', 'OTHER'], n_records),
            'loan_status': np.random.choice([
                'Fully Paid', 'Current', 'Charged Off', 'Late (31-120 days)', 'In Grace Period'
            ], n_records),
            'issue_d': pd.date_range('2015-01', '2023-12', freq='M')[:n_records % 108].tolist() * (n_records // 108 + 1)
        }
        
        df = pd.DataFrame(data)
        df['funded_amnt'] = df['loan_amnt'] * np.random.uniform(0.8, 1.0, n_records)
        df['issue_d'] = pd.to_datetime(df['issue_d']).dt.strftime('%b-%Y')
        
        # à¹€à¸žà¸´à¹ˆà¸¡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸¡à¸µ null values à¸šà¸²à¸‡à¸•à¸±à¸§
        null_columns = ['annual_inc', 'emp_length', 'verification_status']
        for col in null_columns:
            values = np.random.choice(['A', 'B', 'C', None], n_records, p=[0.4, 0.3, 0.2, 0.1])
            df[col] = values
        
        # à¹€à¸žà¸´à¹ˆà¸¡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸¡à¸µ null values à¹€à¸¢à¸­à¸° (à¸ˆà¸°à¸–à¸¹à¸à¸à¸£à¸­à¸‡à¸­à¸­à¸)
        high_null_columns = ['desc', 'mths_since_last_delinq', 'mths_since_last_record']
        for col in high_null_columns:
            values = np.random.choice(['Value', None], n_records, p=[0.2, 0.8])  # 80% null
            df[col] = values
        
        return df
    
    def test_01_data_loading(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥"""
        print("test_data_loading ... ", end="")
        
        # à¸—à¸”à¸ªà¸­à¸šà¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆ
        processor = ETLProcessor()
        result = processor.load_data(self.temp_csv.name)
        
        self.assertTrue(result.success)
        self.assertGreater(result.processed_records, 0)
        self.assertIsNotNone(processor.raw_df)
        
        print("âœ… PASS: à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    
    def test_02_column_type_inference(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸›à¸£à¸°à¹€à¸ à¸—à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ"""
        print("test_column_type_inference ... ", end="")
        
        success, column_types = self.processor.guess_column_types(self.temp_csv.name)
        
        self.assertTrue(success)
        self.assertIsInstance(column_types, dict)
        self.assertGreater(len(column_types), 0)
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸›à¸£à¸°à¹€à¸ à¸—à¸ªà¸³à¸„à¸±à¸
        expected_columns = ['loan_amnt', 'int_rate', 'home_ownership', 'loan_status']
        for col in expected_columns:
            if col in column_types:
                self.assertIsNotNone(column_types[col])
        
        print("âœ… PASS: à¸à¸²à¸£à¸­à¸™à¸¸à¸¡à¸²à¸™à¸›à¸£à¸°à¹€à¸ à¸—à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
    
    def test_03_null_filtering(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸à¸£à¸­à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸¡à¸µ null values à¹€à¸¢à¸­à¸°"""
        print("test_null_filtering ... ", end="")
        
        processor = ETLProcessor()
        processor.load_data(self.temp_csv.name)
        
        original_columns = len(processor.raw_df.columns)
        result = processor.filter_by_null_percentage(max_null_percentage=30)
        
        self.assertTrue(result.success)
        self.assertLessEqual(len(processor.processed_df.columns), original_columns)
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸¡à¸µ null à¹€à¸¢à¸­à¸°à¸–à¸¹à¸à¸à¸£à¸­à¸‡à¸­à¸­à¸
        for col in processor.processed_df.columns:
            null_pct = processor.processed_df[col].isnull().mean() * 100
            self.assertLessEqual(null_pct, 30.0)
        
        print("âœ… PASS: à¸à¸²à¸£à¸à¸£à¸­à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸¡à¸µ null values à¹€à¸¢à¸­à¸°à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    
    def test_04_row_completeness_filtering(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸à¸£à¸­à¸‡à¹à¸–à¸§à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™"""
        print("test_row_completeness_filtering ... ", end="")
        
        processor = ETLProcessor()
        processor.load_data(self.temp_csv.name)
        processor.filter_by_null_percentage()
        
        original_rows = len(processor.processed_df)
        result = processor.filter_by_row_completeness(acceptable_max_null=26)
        
        self.assertTrue(result.success)
        self.assertGreaterEqual(result.processed_records, 0)
        
        print("âœ… PASS: à¸à¸²à¸£à¸à¸£à¸­à¸‡à¹à¸–à¸§à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    
    def test_05_data_transformations(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥"""
        print("test_data_transformations ... ", end="")
        
        # à¹ƒà¸Šà¹‰ processor à¸—à¸µà¹ˆà¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¹‰à¸§
        if hasattr(self.processor, 'processed_df') and self.processor.processed_df is not None:
            result = self.processor.apply_data_transformations()
            
            self.assertTrue(result.success)
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¹à¸›à¸¥à¸‡ issue_d à¹€à¸›à¹‡à¸™ datetime
            if 'issue_d' in self.processor.processed_df.columns:
                self.assertTrue(pd.api.types.is_datetime64_any_dtype(self.processor.processed_df['issue_d']))
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¹à¸›à¸¥à¸‡ int_rate à¹€à¸›à¹‡à¸™ float
            if 'int_rate' in self.processor.processed_df.columns:
                self.assertTrue(pd.api.types.is_numeric_dtype(self.processor.processed_df['int_rate']))
        
        print("âœ… PASS: à¸à¸²à¸£à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    
    def test_06_dimensional_model_creation(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ dimensional model"""
        print("test_dimensional_model_creation ... ", end="")
        
        self.assertTrue(self.processing_result.success)
        self.assertGreater(len(self.processor.dimension_tables), 0)
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š dimension tables à¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸
        expected_dimensions = ['home_ownership', 'loan_status']
        for dim_name in expected_dimensions:
            if dim_name in self.processor.dimension_tables:
                dim_table = self.processor.dimension_tables[dim_name]
                self.assertGreater(len(dim_table), 0)
                self.assertIn(f'{dim_name}_id', dim_table.columns)
        
        print("âœ… PASS: à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ dimensional model à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    
    def test_07_fact_table_creation(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ fact table"""
        print("test_fact_table_creation ... ", end="")
        
        self.assertTrue(self.processing_result.success)
        self.assertIsNotNone(self.processor.fact_table)
        self.assertGreater(len(self.processor.fact_table), 0)
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µ foreign keys
        expected_fks = ['home_ownership_id', 'loan_status_id']
        for fk in expected_fks:
            if fk in self.processor.fact_table.columns:
                # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² foreign key à¹„à¸¡à¹ˆà¸¡à¸µ null
                self.assertEqual(self.processor.fact_table[fk].isnull().sum(), 0)
        
        print("âœ… PASS: à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ fact table à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    
    def test_08_data_quality_framework_integration(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡ Data Quality Framework"""
        print("test_data_quality_framework_integration ... ", end="")
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸¸à¸“à¸ à¸²à¸žà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸žà¸·à¹‰à¸™à¸à¸²à¸™
        if self.processor.processed_df is not None:
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µ null à¹ƒà¸™ final dataset
            null_count = self.processor.processed_df.isnull().sum().sum()
            
            # à¸„à¸³à¸™à¸§à¸“à¸„à¸°à¹à¸™à¸™à¸„à¸¸à¸“à¸ à¸²à¸ž
            total_cells = self.processor.processed_df.shape[0] * self.processor.processed_df.shape[1]
            quality_score = ((total_cells - null_count) / total_cells) * 100 if total_cells > 0 else 0
            
            self.assertGreaterEqual(quality_score, 80.0)  # à¸„à¸°à¹à¸™à¸™à¸„à¸¸à¸“à¸ à¸²à¸žà¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 80%
        
        print(f"âœ… PASS: Data Quality Framework integration - Score: {quality_score:.2f}%")
    
    def test_09_no_null_values_in_final_dataset(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µ null values à¹ƒà¸™ final dataset"""
        print("test_no_null_values_in_final_dataset ... ", end="")
        
        if self.processor.processed_df is not None:
            null_count = self.processor.processed_df.isnull().sum().sum()
            self.assertEqual(null_count, 0, "Final dataset should not contain null values")
        
        print("âœ… PASS: à¹„à¸¡à¹ˆà¸¡à¸µ null values à¹ƒà¸™ final dataset")
    
    def test_10_data_types_correctness(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸‡ data types"""
        print("test_data_types_correctness ... ", end="")
        
        if self.processor.processed_df is not None:
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸
            df = self.processor.processed_df
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š numeric columns
            numeric_columns = ['loan_amnt', 'funded_amnt', 'installment']
            for col in numeric_columns:
                if col in df.columns:
                    self.assertTrue(pd.api.types.is_numeric_dtype(df[col]))
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š datetime columns
            if 'issue_d' in df.columns:
                self.assertTrue(pd.api.types.is_datetime64_any_dtype(df['issue_d']))
        
        print("âœ… PASS: Data types à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”")
    
    def test_11_primary_keys_uniqueness(self):
        """à¸—à¸”à¸ªà¸­à¸š primary keys à¹ƒà¸™ dimension tables à¹„à¸¡à¹ˆà¸‹à¹‰à¸³"""
        print("test_primary_keys_uniqueness ... ", end="")
        
        for dim_name, dim_table in self.processor.dimension_tables.items():
            pk_column = f'{dim_name}_id'
            if pk_column in dim_table.columns:
                # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² primary key à¹„à¸¡à¹ˆà¸‹à¹‰à¸³
                unique_count = dim_table[pk_column].nunique()
                total_count = len(dim_table)
                self.assertEqual(unique_count, total_count, 
                               f"Primary key {pk_column} should be unique")
        
        print("âœ… PASS: Primary keys à¹ƒà¸™ dimension tables à¹„à¸¡à¹ˆà¸‹à¹‰à¸³")
    
    def test_12_foreign_key_integrity(self):
        """à¸—à¸”à¸ªà¸­à¸š foreign key integrity"""
        print("test_foreign_key_integrity ... ", end="")
        
        if self.processor.fact_table is not None:
            fact_table = self.processor.fact_table
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š foreign key integrity
            for dim_name, dim_table in self.processor.dimension_tables.items():
                fk_column = f'{dim_name}_id'
                pk_column = f'{dim_name}_id'
                
                if fk_column in fact_table.columns and pk_column in dim_table.columns:
                    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² foreign key values à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ dimension table
                    fact_fk_values = set(fact_table[fk_column].dropna())
                    dim_pk_values = set(dim_table[pk_column])
                    
                    invalid_fks = fact_fk_values - dim_pk_values
                    self.assertEqual(len(invalid_fks), 0, 
                                   f"Invalid foreign keys found in {fk_column}")
        
        print("âœ… PASS: Foreign keys integrity à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
    
    def test_13_business_logic_validation(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸•à¸£à¸£à¸à¸°à¸—à¸²à¸‡à¸˜à¸¸à¸£à¸à¸´à¸ˆ"""
        print("test_business_logic_validation ... ", end="")
        
        if self.processor.fact_table is not None:
            fact_table = self.processor.fact_table
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š loan amounts à¹€à¸›à¹‡à¸™à¸„à¹ˆà¸²à¸šà¸§à¸
            if 'loan_amnt' in fact_table.columns:
                self.assertTrue((fact_table['loan_amnt'] > 0).all(), 
                              "All loan amounts should be positive")
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š funded_amount <= loan_amount
            if 'loan_amnt' in fact_table.columns and 'funded_amnt' in fact_table.columns:
                self.assertTrue((fact_table['funded_amnt'] <= fact_table['loan_amnt']).all(),
                              "Funded amount should not exceed loan amount")
            
            # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š interest rate à¹ƒà¸™à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¸ªà¸¡à¹€à¸«à¸•à¸¸à¸ªà¸¡à¸œà¸¥ (0-1 for decimal format)
            if 'int_rate' in fact_table.columns:
                self.assertTrue((fact_table['int_rate'] >= 0).all() and 
                              (fact_table['int_rate'] <= 1).all(),
                              "Interest rates should be between 0 and 1")
        
        print("âœ… PASS: à¸•à¸£à¸£à¸à¸°à¸—à¸²à¸‡à¸˜à¸¸à¸£à¸à¸´à¸ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
    
    def test_14_etl_processing_performance(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸žà¸‚à¸­à¸‡ ETL processing"""
        print("test_etl_processing_performance ... ", end="")
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸§à¸¥à¸²à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥
        processing_time = self.processing_result.processing_time
        
        # à¸à¸³à¸«à¸™à¸”à¹€à¸à¸“à¸‘à¹Œà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸¢à¸­à¸¡à¸£à¸±à¸šà¹„à¸”à¹‰ (à¹€à¸Šà¹ˆà¸™ à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 120 à¸§à¸´à¸™à¸²à¸—à¸µ)
        max_acceptable_time = 120.0
        self.assertLessEqual(processing_time, max_acceptable_time,
                           f"Processing time {processing_time:.2f}s exceeds {max_acceptable_time}s")
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸”à¹‰
        self.assertGreater(self.processing_result.processed_records, 0,
                         "Should process at least some records")
        
        print(f"âœ… PASS: Performance OK - {processing_time:.2f}s for {self.processing_result.processed_records} records")
    
    def test_15_error_handling(self):
        """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”"""
        print("test_error_handling ... ", end="")
        
        processor = ETLProcessor()
        
        # à¸—à¸”à¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ
        result = processor.load_data('nonexistent_file.csv')
        self.assertFalse(result.success)
        self.assertGreater(len(result.errors), 0)
        
        # à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸ method à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥
        with self.assertRaises(ValueError):
            processor.filter_by_null_percentage()
        
        print("âœ… PASS: Error handling à¸—à¸³à¸‡à¸²à¸™à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")


def main():
    """à¸£à¸±à¸™à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š ETL à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡"""
    
    # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² test suite
    suite = unittest.TestLoader().loadTestsFromTestCase(TestEnhancedETL)
    
    # à¸£à¸±à¸™à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š
    runner = unittest.TextTestRunner(verbosity=0, stream=open(os.devnull, 'w'))
    result = runner.run(suite)
    
    # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ
    if result.wasSuccessful():
        print("\nâœ… All Enhanced ETL tests passed successfully!")
        return 0
    else:
        print(f"\nâŒ {len(result.failures)} test(s) failed, {len(result.errors)} error(s)")
        for test, traceback in result.failures:
            print(f"FAIL: {test}")
            print(traceback)
        for test, traceback in result.errors:
            print(f"ERROR: {test}")
            print(traceback)
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
